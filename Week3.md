# 딥러닝 모형을 이용한 자연어 처리

## 자연어 처리와 딥러닝

**자연어 처리의 역사**

1980 후반 : 자연어 데이터의 축적, 컴퓨팅 능력이 좋아지면서 규칙보다 통계 기반 방법이 확산되기 시작. 

- 통계적 기계번역 (SMT)은 평행 코퍼스에서 조합 확률이 가장 높은 문장을 선택하는 접근

2000 초반 : 통계 기반 번역 서비스를 제공 

2016 : 신경망 기반 번역 (NMT)로 전환

딥러닝 전환 타임라인 :

- 2013 Word2Vec (단어 임베딩), 2014 Seq2eq (번역), 2015, Attention, 2017 Transformer, 2018 ELMo. BERT 



## 단어 임베딩

**자연어 처리에서 가장 먼저 해야 하는 일로, 단어 또는 문장을 숫자로 표현하는 것**



### 단어 주머니 (Bag of Words, Bow)

- 모든 단어에 인덱스를 주고 원-핫으로 표현하는 가장 단순한 수치화 
- 가장 단순한 방법
- 단점
  - 차원이 높아질수록 희소적이고 비효율적이다. 
  - 단어 간의 유사성을 표현할 수가 없다. 
  - 새로운 단어가 들어올 때 처리가 어렵다. 



### Word2Vec

**단어를 원-핫처럼 '서로 완전히 독립된 기호'가 아니라, 의미 공간의 실수 벡터(보통 50~300차원)으로 표현**

- 2013년 구글의 미코로프가 제안
- 자연어를 학습해 단어를 숫자 벡터들로 분산 표현하는 방법
- 같은 맥락에서 자주 함께 등장하는 단어들의 벡터가 **가깝도록 학습**
  - 원핫 인코딩으로 희소하게 표현된 고차원 단어군을 신경망을 통해 주성분 분석과 같이 **저차원의 의미가 포함된 밀집 벡터**로 다시 표현하는 것
  - **코사인 유사도** 등으로 계산할 수 있음. 



**구조**

<!-- 이미지 1 첨가 -->



**CBOW** (Continuous Bag of Words) 

- 단어의 앞뒤 **n개의 인접단어**로부터 중앙단어를 예측하는 신경망을 만들고, 이 신경망의 가중치 행렬로부터 숫자 벡터를 구하는 방법 
- 즉, **주변 단어를 입력으로 받아 중심 단어를 예측**하는 모델
- 동작원리
  - 주변 단어들의 원-핫 벡터를 임베딩층을 통과시켜 **임베딩 벡터**로 변환
  - 임베딩 벡터들의 평균을 구하여 맥락 벡터를 생성
  - 이 벡터를 두 번째 가중치 행렬에 곱해 중심 단어 후보들의 확률을 계산
  - 실제 중심 단어의 확률을 최대화하도록 학습



**Skip - gram**

- 중앙의 단어로부터 앞뒤 단어를 예측하는 신경망을 만들고 이 신경망의 가중치 행렬로부터 숫자 벡터를 구하는 방법
- CBOW와 반대. **중심 단어를 입력으로 주고, 주변 단어를 예측**하는 모델
- 동작원리
  - 중심 단어를 원-핫 벡터로 입력
  - 임베딩층을 통과하여 중심 단어의 임베딩 벡터를 얻음
  - 이 벡터를 이용해 주변 단어 각각이 나올 확률을 예측
  - 실제 주변 단어들이 예측되도록 파라미터를 학습 

> 계산량이 CBOW보다 많지만, **더 정교한 임베딩** 생성이 가능하다. 



### Seq2Seq

**모형**

<!-- 이미지 2 첨가 -->

- 입력 문장을 순화신경망의 은닉상태를 통해 문장의 내용을 압축한 맥락 벡터로 인코딩 한 이후 그 맥락 벡터를 디코더의 입력으로 사용해서 순차적으로 출력 문장을 생성
- 인코더에서 순차적으로 읽은 중간 단계의 은닉상태 값은 사용되지 않고, 맥락 벡터인 최종 은닉상태만 디코더에 전달된다. 
- 즉, **입력 문장의 단어 시퀀스를 받아 출력 문장 시퀀스를 생성하는 모델**

- 두 개의 RNN (또는 LSTM / GRU)으로 구성되어 있음.



**한계**

1. 문장이 길수록 번역의 품질이 급락함.
   - 은닉상태가 자연어의 복잡한 정보를 담기에 충분히 크지 않을 때, 최종 은닉상태만으로 입력 데이터 전체 문장을 대표하기가 어렵다. (**장기 의존성 문제**)
2. 순환신경망으로 만들어지기에 문장(시퀀스)의 길이가 길어질수록 경사소실 또는 경사폭발 문제가 커진다. 
3. 같은 단어라도 위치와 상황에 따라서 의미가 달라지는 언어의 특성을 반영하기가 어렵다. 



### 어텐션

**Seq2Seq** 모형의 문제를 해결하기 위함. (인코더의 전체 문장 정보를 최종 은닉상태에만 요약하여 디코더에 전달하기 때문에 문장이 길 때 제대로 번역하지를 못한다.)

- 디코더에서 출력 단어의 예측 시점마다 입력되는 전체 문장 정보를 다시 검토하여 관련이 높은 입력 문장의 단어에 더 비중을 두어서 출력 단어를 예측한다. 
- 디코더가 단어를 예측할 때, 입력 문장 (인코더의 모든 hidden state)을 **가중합 (weighted sum)**으로 참조하도록 하는 메커니즘 



**구조**

<!-- 이미지 3 첨가 -->



**Dot-product attention**

- 디코더의 세번째 LSTM 셀에서 출력단어를 예측할 때, 어텐션 메커니즘을 사용하는 모습
- 디코더의 1,2번째 LSTM 셀은 이미 어텐션 메커니즘을 통해 je와 suis를 예측하는 과정을 거쳤다고 가정 
- 세번째 LSTM 셀은 출력단어를 예측하기 위해 인코더의 모든 입력단어들의 정보를 다시 한 번 참고한다. 

> 그림 설명
>
> - 빨간 직사각형 크기 : 소프트맥수 함수의 결과값의 크기
>   - 사각형의 크기가 클수록, 도움이 되는 정도가 큼
> - 결과적으로 디코더는 출력 단어를 더 정확하게 예측할 확률이 높아진다. 

**다양한 종류의 어텐션들**

<!-- 이미지 4 첨가 -->



## 트랜스포머 (Transformer)

Seq2Seq 모형에서 순환신경망을 제거하고, 어텐션 메커니즘만 이용한 트랜스포머를 제안

> 2018년 소개된 BERT를 비롯한 문장 임베딩 모형들의 근간이 됨.

**Seq2Seq 모형과 트랜스포머**

- Seq2Seq 모형의 병목현상 : 다양하고 복잡한 문장들을 맥락 벡터에 담아내기에는 은닉상태의 크기가 부족해 최종 은닉상태만으로 입력 데이터 전체 문장을 대표하기 어려운 **장기 의존성** 문제
- 어텐션 메커니즘을 이용해 출력 문장의 매 토큰마다 입력 문장의 모든 토큰의 정보를 바탕으로 맥락 벡터를 계산하여 입력 문장의 특성을 보다 잘 반영할 수 있게 되었다. 
- 순환신경망에 행렬연산이 추가되어서 연산의 부담이 커지고, 순차적으로 연산할 수 밖에 없는 순환신경망이라는 제약이 있었다. 

> 이 제약을 극복하기 위해 제안된 모형 => 트랜스포머 
>
> **Recurrent 구조를 완전히 제거하고, Attention 만으로 시퀀스를 처리하는 모델**



**트랜스포머의 구조**

<!-- 이미지 5 첨가 -->

- 왼쪽의 인코더와 오른쪽의 디코더로 이루어져 있다. 
  - 여전히 **Encoder - Decoder** 형태이지만, **RNN 대신 전부 Self-Attention과 Feed-Forward Layer**로 구성
- 인코더 
  - 입력문장을 구성하는 토큰의 시퀀스들을 받아서 임베딩층을 거쳐 정해진 크기의 벡터로 변형
  - 여기에 위치 인코딩을 더해서 토큰의 위치 정보를 가미한 후에 N개의 인코더 트랜스포머 블록을 거친다. 
  - 입력과 출력의 크기 = `문장의 길이' X '임베딩 크기'`
  - 최종 출력은 N개의 디코더 트랜스포머 블록을 거칠 때마다 여러 개의 어텐션으로 구서된 멀티-헤드 어텐션의 입력으로 사용 
- 디코더 
  - 위의 정보를 받고 난 이후 디코더 트랜스포머 블록을 통과하고 나면, 마지막으로 밀집신경망을 거친 후에 소프트맥스 함수를 적용해 토큰을 예측함. 



### 입력과 임베딩

- 원-핫 벡터에서 해당 토큰의 인덱스로 입력을 받는다.
- 문장 벡터 전체를 하나의 행렬로 간주하고, 행렬 연산을 진행하기에 연산시간이 획기적으로 줄어든다. 
- 전체 문장을 한 번에 신경망에 입력 -> 단, 추론할 때 디코더는 순차적으로 토큰을 받음. 
- 인코더와 디코더는 같은 임베딩 층을 고려함. 

> 트랜스포머는 구조상 입력 시퀀스 전체가 입력되기에 토큰들 간의 순서를 알 수가 없다. 
>
> - 이를 보완하기 위해 위치를 나타내주는 정보를 임베딩에 더하는 **위치 인코딩**을 이용함. 



### 셀프 어텐션

36p 부터 진행 더 하기 







